{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
       "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  \n",
       "1         40.731152                  N            663  \n",
       "2         40.710087                  N           2124  \n",
       "3         40.706718                  N            429  \n",
       "4         40.782520                  N            435  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from datetime(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n",
    "train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\n",
    "train.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\n",
    "train.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\n",
    "train.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "train.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n",
    "train.loc[:, 'pickup_dt_bin'] = (train['pickup_dt'] // (3 * 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from longitude and latitude(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    train[['dropoff_latitude', 'dropoff_longitude']].values))\n",
    "\n",
    "def rotate_distance(lat1,lng1,lat2,lng2):\n",
    "    phi = (36.1/180)*np.pi\n",
    "    lat1_rot = lat1*np.sin(phi)+lng1*np.cos(phi)\n",
    "    lng1_rot = lat1*np.cos(phi)-lng1*np.sin(phi)\n",
    "    lat2_rot = lat2*np.sin(phi)+lng2*np.cos(phi)\n",
    "    lng2_rot = lat2*np.cos(phi)-lng2*np.sin(phi)\n",
    "    rotate_distance = np.abs(lat1_rot-lat2_rot)+np.abs(lng1_rot-lng2_rot)\n",
    "    return rotate_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(coords)\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n",
    "train.loc[:, 'rotate_distance'] = rotate_distance(train['pickup_latitude'].values,train['pickup_longitude'].values,train['dropoff_latitude'].values,train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n",
    "train.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n",
    "train.loc[:, 'center_lat_bin'] = np.round(train['center_latitude'], 2)\n",
    "train.loc[:, 'center_long_bin'] = np.round(train['center_longitude'], 2)\n",
    "sample_ind = np.random.permutation(len(coords))[:500000]\n",
    "kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])\n",
    "train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\n",
    "train.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'avg_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log_trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gby_col in ['pickup_hour', 'pickup_date', 'pickup_dt_bin',\n",
    "               'pickup_week_hour', 'pickup_cluster', 'dropoff_cluster']:\n",
    "    gby = train.groupby(gby_col).mean()[['avg_speed_h', 'avg_speed_m', 'log_trip_duration']]\n",
    "    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n",
    "    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n",
    "\n",
    "for gby_cols in [['center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'pickup_cluster'],  ['pickup_hour', 'dropoff_cluster'],\n",
    "                 ['pickup_cluster', 'dropoff_cluster']]:\n",
    "    coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "    coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "    coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "    coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "    coord_stats.columns = gby_cols + ['avg_speed_h_%s' % '_'.join(gby_cols), 'cnt_%s' %  '_'.join(gby_cols)]\n",
    "    train = pd.merge(train, coord_stats, how='left', on=gby_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "group_freq = '60min'\n",
    "df_all = train[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "train.loc[:, 'pickup_datetime_group'] = train['pickup_datetime'].dt.round(group_freq)\n",
    "\n",
    "# Count trips over 60min\n",
    "df_counts = df_all.set_index('pickup_datetime')[['id']].sort_index()\n",
    "df_counts['count_60min'] = df_counts.isnull().rolling(group_freq).count()['id']\n",
    "train = train.merge(df_counts, on='id', how='left')\n",
    "\n",
    "# Count how many trips are going to each cluster over time\n",
    "dropoff_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'dropoff_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('dropoff_cluster').rolling('240min').mean() \\\n",
    "    .drop('dropoff_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'dropoff_cluster_count'})\n",
    "\n",
    "train['dropoff_cluster_count'] = train[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Count how many trips are going from each cluster over time\n",
    "df_all = train[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "pickup_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'pickup_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('pickup_cluster').rolling('240min').mean() \\\n",
    "    .drop('pickup_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'pickup_cluster_count'})\n",
    "\n",
    "train['pickup_cluster_count'] = train[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_speed_h_pickup_hour_pickup_cluster</th>\n",
       "      <th>cnt_pickup_hour_pickup_cluster</th>\n",
       "      <th>avg_speed_h_pickup_hour_dropoff_cluster</th>\n",
       "      <th>cnt_pickup_hour_dropoff_cluster</th>\n",
       "      <th>avg_speed_h_pickup_cluster_dropoff_cluster</th>\n",
       "      <th>cnt_pickup_cluster_dropoff_cluster</th>\n",
       "      <th>pickup_datetime_group</th>\n",
       "      <th>count_60min</th>\n",
       "      <th>dropoff_cluster_count</th>\n",
       "      <th>pickup_cluster_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2.998304</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.951780</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>2.793804</td>\n",
       "      <td>921.0</td>\n",
       "      <td>2016-03-14 17:00:00</td>\n",
       "      <td>391.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794508</td>\n",
       "      <td>425.0</td>\n",
       "      <td>3.791164</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>2.829591</td>\n",
       "      <td>313.0</td>\n",
       "      <td>2016-06-12 01:00:00</td>\n",
       "      <td>461.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2.989169</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>3.485523</td>\n",
       "      <td>576.0</td>\n",
       "      <td>4.205389</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2016-01-19 12:00:00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.056109</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>4.541152</td>\n",
       "      <td>532.0</td>\n",
       "      <td>3.762733</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2016-04-06 20:00:00</td>\n",
       "      <td>563.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.128996</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>3.583851</td>\n",
       "      <td>676.0</td>\n",
       "      <td>4.658722</td>\n",
       "      <td>726.0</td>\n",
       "      <td>2016-03-26 14:00:00</td>\n",
       "      <td>432.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55 2016-03-14 17:32:30   \n",
       "1  id2377394          1 2016-06-12 00:43:35 2016-06-12 00:54:38   \n",
       "2  id3858529          2 2016-01-19 11:35:24 2016-01-19 12:10:48   \n",
       "3  id3504673          2 2016-04-06 19:32:31 2016-04-06 19:39:40   \n",
       "4  id2181028          2 2016-03-26 13:30:55 2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag          ...           \\\n",
       "0         40.765602                  N          ...            \n",
       "1         40.731152                  N          ...            \n",
       "2         40.710087                  N          ...            \n",
       "3         40.706718                  N          ...            \n",
       "4         40.782520                  N          ...            \n",
       "\n",
       "   avg_speed_h_pickup_hour_pickup_cluster cnt_pickup_hour_pickup_cluster  \\\n",
       "0                                2.998304                         2020.0   \n",
       "1                                4.794508                          425.0   \n",
       "2                                2.989169                         1119.0   \n",
       "3                                4.056109                         1095.0   \n",
       "4                                4.128996                         1527.0   \n",
       "\n",
       "   avg_speed_h_pickup_hour_dropoff_cluster  cnt_pickup_hour_dropoff_cluster  \\\n",
       "0                                 2.951780                           1498.0   \n",
       "1                                 3.791164                           1461.0   \n",
       "2                                 3.485523                            576.0   \n",
       "3                                 4.541152                            532.0   \n",
       "4                                 3.583851                            676.0   \n",
       "\n",
       "   avg_speed_h_pickup_cluster_dropoff_cluster  \\\n",
       "0                                    2.793804   \n",
       "1                                    2.829591   \n",
       "2                                    4.205389   \n",
       "3                                    3.762733   \n",
       "4                                    4.658722   \n",
       "\n",
       "   cnt_pickup_cluster_dropoff_cluster  pickup_datetime_group  count_60min  \\\n",
       "0                               921.0    2016-03-14 17:00:00        391.0   \n",
       "1                               313.0    2016-06-12 01:00:00        461.0   \n",
       "2                               115.0    2016-01-19 12:00:00        380.0   \n",
       "3                               330.0    2016-04-06 20:00:00        563.0   \n",
       "4                               726.0    2016-03-26 14:00:00        432.0   \n",
       "\n",
       "   dropoff_cluster_count  pickup_cluster_count  \n",
       "0                  10.50                 18.50  \n",
       "1                  11.75                  2.25  \n",
       "2                   3.75                 10.00  \n",
       "3                   3.00                  7.25  \n",
       "4                   4.75                  9.25  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2016</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-1-2016</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-1-2016</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-1-2016</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-1-2016</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  maximum temperature  minimum temperature  average temperature  \\\n",
       "0  1-1-2016                   42                   34                 38.0   \n",
       "1  2-1-2016                   40                   32                 36.0   \n",
       "2  3-1-2016                   45                   35                 40.0   \n",
       "3  4-1-2016                   36                   14                 25.0   \n",
       "4  5-1-2016                   29                   11                 20.0   \n",
       "\n",
       "  precipitation snow fall snow depth  \n",
       "0          0.00       0.0          0  \n",
       "1          0.00       0.0          0  \n",
       "2          0.00       0.0          0  \n",
       "3          0.00       0.0          0  \n",
       "4          0.00       0.0          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('./weather.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "weather['precipitation'][weather['precipitation']=='T']=0\n",
    "weather['snow fall'][weather['snow fall']=='T']=0\n",
    "weather['snow depth'][weather['snow depth']=='T']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2016</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-1-2016</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-1-2016</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-1-2016</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-1-2016</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  maximum temperature  minimum temperature  average temperature  \\\n",
       "0  1-1-2016                   42                   34                 38.0   \n",
       "1  2-1-2016                   40                   32                 36.0   \n",
       "2  3-1-2016                   45                   35                 40.0   \n",
       "3  4-1-2016                   36                   14                 25.0   \n",
       "4  5-1-2016                   29                   11                 20.0   \n",
       "\n",
       "  precipitation snow fall snow depth  \n",
       "0          0.00       0.0          0  \n",
       "1          0.00       0.0          0  \n",
       "2          0.00       0.0          0  \n",
       "3          0.00       0.0          0  \n",
       "4          0.00       0.0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather['precipitation'] = pd.to_numeric(weather['precipitation'])\n",
    "weather['snow fall']= pd.to_numeric(weather['snow fall'])\n",
    "weather['snow depth']= pd.to_numeric(weather['snow depth'])\n",
    "weather.rename(columns={'date':'pickup_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pickup_date = pd.to_datetime(train.pickup_date)\n",
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "train_merge_weather = pd.merge(train,weather,on='pickup_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_datetime_group</th>\n",
       "      <th>count_60min</th>\n",
       "      <th>dropoff_cluster_count</th>\n",
       "      <th>pickup_cluster_count</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 17:00:00</td>\n",
       "      <td>391.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2129090</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-14 14:05:39</td>\n",
       "      <td>2016-03-14 14:28:05</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.975090</td>\n",
       "      <td>40.758766</td>\n",
       "      <td>-73.953201</td>\n",
       "      <td>40.765068</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 14:00:00</td>\n",
       "      <td>414.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>15.75</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0256505</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-14 15:04:38</td>\n",
       "      <td>2016-03-14 15:16:13</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994484</td>\n",
       "      <td>40.745087</td>\n",
       "      <td>-73.998993</td>\n",
       "      <td>40.722710</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 15:00:00</td>\n",
       "      <td>476.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3863815</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 04:24:36</td>\n",
       "      <td>2016-03-14 04:37:11</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.944359</td>\n",
       "      <td>40.714489</td>\n",
       "      <td>-73.910530</td>\n",
       "      <td>40.709492</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 04:00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id3817493</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 14:57:56</td>\n",
       "      <td>2016-03-14 15:15:26</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.952881</td>\n",
       "      <td>40.766468</td>\n",
       "      <td>-73.978630</td>\n",
       "      <td>40.761921</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 15:00:00</td>\n",
       "      <td>478.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9.50</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55 2016-03-14 17:32:30   \n",
       "1  id2129090          1 2016-03-14 14:05:39 2016-03-14 14:28:05   \n",
       "2  id0256505          1 2016-03-14 15:04:38 2016-03-14 15:16:13   \n",
       "3  id3863815          2 2016-03-14 04:24:36 2016-03-14 04:37:11   \n",
       "4  id3817493          2 2016-03-14 14:57:56 2016-03-14 15:15:26   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.975090        40.758766         -73.953201   \n",
       "2                1        -73.994484        40.745087         -73.998993   \n",
       "3                3        -73.944359        40.714489         -73.910530   \n",
       "4                1        -73.952881        40.766468         -73.978630   \n",
       "\n",
       "   dropoff_latitude  store_and_fwd_flag     ...      pickup_datetime_group  \\\n",
       "0         40.765602                   0     ...        2016-03-14 17:00:00   \n",
       "1         40.765068                   0     ...        2016-03-14 14:00:00   \n",
       "2         40.722710                   0     ...        2016-03-14 15:00:00   \n",
       "3         40.709492                   0     ...        2016-03-14 04:00:00   \n",
       "4         40.761921                   0     ...        2016-03-14 15:00:00   \n",
       "\n",
       "  count_60min  dropoff_cluster_count  pickup_cluster_count  \\\n",
       "0       391.0                  10.50                 18.50   \n",
       "1       414.0                   5.25                 15.75   \n",
       "2       476.0                   4.00                  8.50   \n",
       "3        37.0                   0.00                  0.00   \n",
       "4       478.0                   7.75                  9.50   \n",
       "\n",
       "   maximum temperature  minimum temperature  average temperature  \\\n",
       "0                   51                   40                 45.5   \n",
       "1                   51                   40                 45.5   \n",
       "2                   51                   40                 45.5   \n",
       "3                   51                   40                 45.5   \n",
       "4                   51                   40                 45.5   \n",
       "\n",
       "   precipitation  snow fall  snow depth  \n",
       "0           0.29        0.0           0  \n",
       "1           0.29        0.0           0  \n",
       "2           0.29        0.0           0  \n",
       "3           0.29        0.0           0  \n",
       "4           0.29        0.0           0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_weather['pickup_date'] = train_merge_weather['pickup_datetime'].dt.date\n",
    "train_merge_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(train.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23233\tvalid-rmse:4.23351\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.405926\tvalid-rmse:0.42601\n",
      "[20]\ttrain-rmse:0.365703\tvalid-rmse:0.397499\n",
      "[30]\ttrain-rmse:0.357206\tvalid-rmse:0.395381\n",
      "[40]\ttrain-rmse:0.350104\tvalid-rmse:0.394734\n",
      "[50]\ttrain-rmse:0.344619\tvalid-rmse:0.394276\n",
      "[59]\ttrain-rmse:0.34003\tvalid-rmse:0.393948\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(xgb_pars, dtrain, 60, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add weather features(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23254\tvalid-rmse:4.23378\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.403017\tvalid-rmse:0.41942\n",
      "[20]\ttrain-rmse:0.368721\tvalid-rmse:0.395131\n",
      "[30]\ttrain-rmse:0.357988\tvalid-rmse:0.392021\n",
      "[40]\ttrain-rmse:0.35045\tvalid-rmse:0.390913\n",
      "[50]\ttrain-rmse:0.342965\tvalid-rmse:0.390495\n",
      "[60]\ttrain-rmse:0.33843\tvalid-rmse:0.390402\n",
      "[70]\ttrain-rmse:0.334798\tvalid-rmse:0.390729\n",
      "[79]\ttrain-rmse:0.33122\tvalid-rmse:0.390839\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 80, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bike count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25242</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-05-30 15:23:05</td>\n",
       "      <td>2016-05-30 15:52:59</td>\n",
       "      <td>-73.976485</td>\n",
       "      <td>40.759923</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20900</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24 19:56:47</td>\n",
       "      <td>2016-04-24 20:02:17</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18792</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-25 15:08:38</td>\n",
       "      <td>2016-06-25 15:15:57</td>\n",
       "      <td>-73.991908</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-74.005524</td>\n",
       "      <td>40.711464</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17420</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-28 18:14:17</td>\n",
       "      <td>2016-06-28 18:35:25</td>\n",
       "      <td>-73.986569</td>\n",
       "      <td>40.701485</td>\n",
       "      <td>-73.989900</td>\n",
       "      <td>40.714275</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22403</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-11 17:10:33</td>\n",
       "      <td>2016-06-11 17:14:44</td>\n",
       "      <td>-73.989551</td>\n",
       "      <td>40.740343</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  25242          2  2016-05-30 15:23:05  2016-05-30 15:52:59   \n",
       "1  20900          1  2016-04-24 19:56:47  2016-04-24 20:02:17   \n",
       "2  18792          1  2016-06-25 15:08:38  2016-06-25 15:15:57   \n",
       "3  17420          1  2016-06-28 18:14:17  2016-06-28 18:35:25   \n",
       "4  22403          1  2016-06-11 17:10:33  2016-06-11 17:14:44   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.976485        40.759923         -74.002150         40.730386   \n",
       "1        -74.003664        40.743174         -74.002150         40.730386   \n",
       "2        -73.991908        40.716059         -74.005524         40.711464   \n",
       "3        -73.986569        40.701485         -73.989900         40.714275   \n",
       "4        -73.989551        40.740343         -73.990093         40.737050   \n",
       "\n",
       "   trip_duration  \n",
       "0           1794  \n",
       "1            329  \n",
       "2            438  \n",
       "3           1268  \n",
       "4            251  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df = pd.read_csv('./City Bike.csv')\n",
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df['pickup_datetime'] = pd.to_datetime(bike_df['pickup_datetime'])\n",
    "bike_df.loc[:,'pickup_date'] = bike_df['pickup_datetime'].dt.date\n",
    "bike_df_date = bike_df.groupby('pickup_date').count()[['id']]\n",
    "bike_df_date.rename(columns={'id':'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df_date.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_weather_bike = pd.merge(train_merge_weather,bike_df_date,on='pickup_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23475\tvalid-rmse:4.23697\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.405009\tvalid-rmse:0.420151\n",
      "[20]\ttrain-rmse:0.366503\tvalid-rmse:0.392258\n",
      "[30]\ttrain-rmse:0.357009\tvalid-rmse:0.390775\n",
      "[40]\ttrain-rmse:0.349038\tvalid-rmse:0.389274\n",
      "[50]\ttrain-rmse:0.344041\tvalid-rmse:0.388875\n",
      "[60]\ttrain-rmse:0.340667\tvalid-rmse:0.388936\n",
      "[70]\ttrain-rmse:0.337429\tvalid-rmse:0.389097\n",
      "[79]\ttrain-rmse:0.334928\tvalid-rmse:0.388912\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather_bike.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather_bike.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather_bike['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather_bike[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 80, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add hoilday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_holidays = holidays.CountryHoliday('US',state='NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holidays=pd.Series([each in ny_holidays for each in train_merge_weather_bike['pickup_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_weather_bike['is_holidays'] = is_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23475\tvalid-rmse:4.23697\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.409759\tvalid-rmse:0.424811\n",
      "[20]\ttrain-rmse:0.368623\tvalid-rmse:0.395862\n",
      "[30]\ttrain-rmse:0.357766\tvalid-rmse:0.39196\n",
      "[40]\ttrain-rmse:0.351049\tvalid-rmse:0.390454\n",
      "[50]\ttrain-rmse:0.345748\tvalid-rmse:0.389685\n",
      "[60]\ttrain-rmse:0.341157\tvalid-rmse:0.389745\n",
      "[70]\ttrain-rmse:0.338642\tvalid-rmse:0.389795\n",
      "[79]\ttrain-rmse:0.335583\tvalid-rmse:0.389911\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather_bike.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather_bike.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather_bike['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather_bike[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 80, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
