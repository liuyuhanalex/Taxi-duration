{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
       "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  \n",
       "1         40.731152                  N            663  \n",
       "2         40.710087                  N           2124  \n",
       "3         40.706718                  N            429  \n",
       "4         40.782520                  N            435  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from datetime(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n",
    "train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\n",
    "train.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\n",
    "train.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\n",
    "train.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "train.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n",
    "train.loc[:, 'pickup_dt_bin'] = (train['pickup_dt'] // (3 * 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from longitude and latitude(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    train[['dropoff_latitude', 'dropoff_longitude']].values))\n",
    "\n",
    "def rotate_distance(lat1,lng1,lat2,lng2):\n",
    "    phi = (36.1/180)*np.pi\n",
    "    lat1_rot = lat1*np.sin(phi)+lng1*np.cos(phi)\n",
    "    lng1_rot = lat1*np.cos(phi)-lng1*np.sin(phi)\n",
    "    lat2_rot = lat2*np.sin(phi)+lng2*np.cos(phi)\n",
    "    lng2_rot = lat2*np.cos(phi)-lng2*np.sin(phi)\n",
    "    rotate_distance = np.abs(lat1_rot-lat2_rot)+np.abs(lng1_rot-lng2_rot)\n",
    "    return rotate_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(coords)\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n",
    "train.loc[:, 'rotate_distance'] = rotate_distance(train['pickup_latitude'].values,train['pickup_longitude'].values,train['dropoff_latitude'].values,train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n",
    "train.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n",
    "train.loc[:, 'center_lat_bin'] = np.round(train['center_latitude'], 2)\n",
    "train.loc[:, 'center_long_bin'] = np.round(train['center_longitude'], 2)\n",
    "sample_ind = np.random.permutation(len(coords))[:500000]\n",
    "kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])\n",
    "train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\n",
    "train.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'avg_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log_trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gby_col in ['pickup_hour', 'pickup_date', 'pickup_dt_bin',\n",
    "               'pickup_week_hour', 'pickup_cluster', 'dropoff_cluster']:\n",
    "    gby = train.groupby(gby_col).mean()[['avg_speed_h', 'avg_speed_m', 'log_trip_duration']]\n",
    "    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n",
    "    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n",
    "\n",
    "for gby_cols in [['center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'pickup_cluster'],  ['pickup_hour', 'dropoff_cluster'],\n",
    "                 ['pickup_cluster', 'dropoff_cluster']]:\n",
    "    coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "    coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "    coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "    coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "    coord_stats.columns = gby_cols + ['avg_speed_h_%s' % '_'.join(gby_cols), 'cnt_%s' %  '_'.join(gby_cols)]\n",
    "    train = pd.merge(train, coord_stats, how='left', on=gby_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "group_freq = '60min'\n",
    "df_all = train[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "train.loc[:, 'pickup_datetime_group'] = train['pickup_datetime'].dt.round(group_freq)\n",
    "\n",
    "# Count trips over 60min\n",
    "df_counts = df_all.set_index('pickup_datetime')[['id']].sort_index()\n",
    "df_counts['count_60min'] = df_counts.isnull().rolling(group_freq).count()['id']\n",
    "train = train.merge(df_counts, on='id', how='left')\n",
    "\n",
    "# Count how many trips are going to each cluster over time\n",
    "dropoff_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'dropoff_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('dropoff_cluster').rolling('240min').mean() \\\n",
    "    .drop('dropoff_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'dropoff_cluster_count'})\n",
    "\n",
    "train['dropoff_cluster_count'] = train[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Count how many trips are going from each cluster over time\n",
    "df_all = train[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "pickup_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'pickup_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('pickup_cluster').rolling('240min').mean() \\\n",
    "    .drop('pickup_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'pickup_cluster_count'})\n",
    "\n",
    "train['pickup_cluster_count'] = train[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_speed_h_pickup_hour_pickup_cluster</th>\n",
       "      <th>cnt_pickup_hour_pickup_cluster</th>\n",
       "      <th>avg_speed_h_pickup_hour_dropoff_cluster</th>\n",
       "      <th>cnt_pickup_hour_dropoff_cluster</th>\n",
       "      <th>avg_speed_h_pickup_cluster_dropoff_cluster</th>\n",
       "      <th>cnt_pickup_cluster_dropoff_cluster</th>\n",
       "      <th>pickup_datetime_group</th>\n",
       "      <th>count_60min</th>\n",
       "      <th>dropoff_cluster_count</th>\n",
       "      <th>pickup_cluster_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2.918342</td>\n",
       "      <td>2071.0</td>\n",
       "      <td>2.853921</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>2.795612</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>2016-03-14 17:00:00</td>\n",
       "      <td>391.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>20.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.377937</td>\n",
       "      <td>757.0</td>\n",
       "      <td>3.733392</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2.996678</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2016-06-12 01:00:00</td>\n",
       "      <td>461.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>3.075210</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>4.345870</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>4.670487</td>\n",
       "      <td>363.0</td>\n",
       "      <td>2016-01-19 12:00:00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.158306</td>\n",
       "      <td>545.0</td>\n",
       "      <td>4.423248</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>3.066370</td>\n",
       "      <td>501.0</td>\n",
       "      <td>2016-04-06 20:00:00</td>\n",
       "      <td>563.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>4.177452</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>3.620640</td>\n",
       "      <td>596.0</td>\n",
       "      <td>4.359885</td>\n",
       "      <td>542.0</td>\n",
       "      <td>2016-03-26 14:00:00</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55 2016-03-14 17:32:30   \n",
       "1  id2377394          1 2016-06-12 00:43:35 2016-06-12 00:54:38   \n",
       "2  id3858529          2 2016-01-19 11:35:24 2016-01-19 12:10:48   \n",
       "3  id3504673          2 2016-04-06 19:32:31 2016-04-06 19:39:40   \n",
       "4  id2181028          2 2016-03-26 13:30:55 2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag          ...           \\\n",
       "0         40.765602                  N          ...            \n",
       "1         40.731152                  N          ...            \n",
       "2         40.710087                  N          ...            \n",
       "3         40.706718                  N          ...            \n",
       "4         40.782520                  N          ...            \n",
       "\n",
       "   avg_speed_h_pickup_hour_pickup_cluster cnt_pickup_hour_pickup_cluster  \\\n",
       "0                                2.918342                         2071.0   \n",
       "1                                4.377937                          757.0   \n",
       "2                                3.075210                         1722.0   \n",
       "3                                4.158306                          545.0   \n",
       "4                                4.177452                         1395.0   \n",
       "\n",
       "   avg_speed_h_pickup_hour_dropoff_cluster  cnt_pickup_hour_dropoff_cluster  \\\n",
       "0                                 2.853921                           1652.0   \n",
       "1                                 3.733392                            708.0   \n",
       "2                                 4.345870                           1339.0   \n",
       "3                                 4.423248                           1130.0   \n",
       "4                                 3.620640                            596.0   \n",
       "\n",
       "   avg_speed_h_pickup_cluster_dropoff_cluster  \\\n",
       "0                                    2.795612   \n",
       "1                                    2.996678   \n",
       "2                                    4.670487   \n",
       "3                                    3.066370   \n",
       "4                                    4.359885   \n",
       "\n",
       "   cnt_pickup_cluster_dropoff_cluster  pickup_datetime_group  count_60min  \\\n",
       "0                              1065.0    2016-03-14 17:00:00        391.0   \n",
       "1                               302.0    2016-06-12 01:00:00        461.0   \n",
       "2                               363.0    2016-01-19 12:00:00        380.0   \n",
       "3                               501.0    2016-04-06 20:00:00        563.0   \n",
       "4                               542.0    2016-03-26 14:00:00        432.0   \n",
       "\n",
       "   dropoff_cluster_count  pickup_cluster_count  \n",
       "0                  11.00             20.250000  \n",
       "1                   6.50              5.333333  \n",
       "2                   7.25             12.500000  \n",
       "3                   8.00              3.500000  \n",
       "4                   2.50              7.750000  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2016</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-1-2016</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-1-2016</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-1-2016</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-1-2016</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  maximum temperature  minimum temperature  average temperature  \\\n",
       "0  1-1-2016                   42                   34                 38.0   \n",
       "1  2-1-2016                   40                   32                 36.0   \n",
       "2  3-1-2016                   45                   35                 40.0   \n",
       "3  4-1-2016                   36                   14                 25.0   \n",
       "4  5-1-2016                   29                   11                 20.0   \n",
       "\n",
       "  precipitation snow fall snow depth  \n",
       "0          0.00       0.0          0  \n",
       "1          0.00       0.0          0  \n",
       "2          0.00       0.0          0  \n",
       "3          0.00       0.0          0  \n",
       "4          0.00       0.0          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('./weather.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "weather['precipitation'][weather['precipitation']=='T']=0\n",
    "weather['snow fall'][weather['snow fall']=='T']=0\n",
    "weather['snow depth'][weather['snow depth']=='T']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2016</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-1-2016</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-1-2016</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-1-2016</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-1-2016</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  maximum temperature  minimum temperature  average temperature  \\\n",
       "0  1-1-2016                   42                   34                 38.0   \n",
       "1  2-1-2016                   40                   32                 36.0   \n",
       "2  3-1-2016                   45                   35                 40.0   \n",
       "3  4-1-2016                   36                   14                 25.0   \n",
       "4  5-1-2016                   29                   11                 20.0   \n",
       "\n",
       "  precipitation snow fall snow depth  \n",
       "0          0.00       0.0          0  \n",
       "1          0.00       0.0          0  \n",
       "2          0.00       0.0          0  \n",
       "3          0.00       0.0          0  \n",
       "4          0.00       0.0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather['precipitation'] = pd.to_numeric(weather['precipitation'])\n",
    "weather['snow fall']= pd.to_numeric(weather['snow fall'])\n",
    "weather['snow depth']= pd.to_numeric(weather['snow depth'])\n",
    "weather.rename(columns={'date':'pickup_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pickup_date = pd.to_datetime(train.pickup_date)\n",
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "train_merge_weather = pd.merge(train,weather,on='pickup_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_datetime_group</th>\n",
       "      <th>count_60min</th>\n",
       "      <th>dropoff_cluster_count</th>\n",
       "      <th>pickup_cluster_count</th>\n",
       "      <th>maximum temperature</th>\n",
       "      <th>minimum temperature</th>\n",
       "      <th>average temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow fall</th>\n",
       "      <th>snow depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 17:00:00</td>\n",
       "      <td>391.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>20.25</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2129090</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-14 14:05:39</td>\n",
       "      <td>2016-03-14 14:28:05</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.975090</td>\n",
       "      <td>40.758766</td>\n",
       "      <td>-73.953201</td>\n",
       "      <td>40.765068</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 14:00:00</td>\n",
       "      <td>414.0</td>\n",
       "      <td>12.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0256505</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-14 15:04:38</td>\n",
       "      <td>2016-03-14 15:16:13</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994484</td>\n",
       "      <td>40.745087</td>\n",
       "      <td>-73.998993</td>\n",
       "      <td>40.722710</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 15:00:00</td>\n",
       "      <td>476.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3863815</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 04:24:36</td>\n",
       "      <td>2016-03-14 04:37:11</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.944359</td>\n",
       "      <td>40.714489</td>\n",
       "      <td>-73.910530</td>\n",
       "      <td>40.709492</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 04:00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id3817493</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 14:57:56</td>\n",
       "      <td>2016-03-14 15:15:26</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.952881</td>\n",
       "      <td>40.766468</td>\n",
       "      <td>-73.978630</td>\n",
       "      <td>40.761921</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-14 15:00:00</td>\n",
       "      <td>478.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>14.25</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55 2016-03-14 17:32:30   \n",
       "1  id2129090          1 2016-03-14 14:05:39 2016-03-14 14:28:05   \n",
       "2  id0256505          1 2016-03-14 15:04:38 2016-03-14 15:16:13   \n",
       "3  id3863815          2 2016-03-14 04:24:36 2016-03-14 04:37:11   \n",
       "4  id3817493          2 2016-03-14 14:57:56 2016-03-14 15:15:26   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.975090        40.758766         -73.953201   \n",
       "2                1        -73.994484        40.745087         -73.998993   \n",
       "3                3        -73.944359        40.714489         -73.910530   \n",
       "4                1        -73.952881        40.766468         -73.978630   \n",
       "\n",
       "   dropoff_latitude  store_and_fwd_flag     ...      pickup_datetime_group  \\\n",
       "0         40.765602                   0     ...        2016-03-14 17:00:00   \n",
       "1         40.765068                   0     ...        2016-03-14 14:00:00   \n",
       "2         40.722710                   0     ...        2016-03-14 15:00:00   \n",
       "3         40.709492                   0     ...        2016-03-14 04:00:00   \n",
       "4         40.761921                   0     ...        2016-03-14 15:00:00   \n",
       "\n",
       "  count_60min  dropoff_cluster_count  pickup_cluster_count  \\\n",
       "0       391.0                  11.00                 20.25   \n",
       "1       414.0                  12.25                 10.00   \n",
       "2       476.0                   3.50                  4.50   \n",
       "3        37.0                   0.00                  0.00   \n",
       "4       478.0                  11.75                 14.25   \n",
       "\n",
       "   maximum temperature  minimum temperature  average temperature  \\\n",
       "0                   51                   40                 45.5   \n",
       "1                   51                   40                 45.5   \n",
       "2                   51                   40                 45.5   \n",
       "3                   51                   40                 45.5   \n",
       "4                   51                   40                 45.5   \n",
       "\n",
       "   precipitation  snow fall  snow depth  \n",
       "0           0.29        0.0           0  \n",
       "1           0.29        0.0           0  \n",
       "2           0.29        0.0           0  \n",
       "3           0.29        0.0           0  \n",
       "4           0.29        0.0           0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_weather['pickup_date'] = train_merge_weather['pickup_datetime'].dt.date\n",
    "train_merge_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGB without additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(train.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23222\tvalid-rmse:4.23337\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.405777\tvalid-rmse:0.425402\n",
      "[20]\ttrain-rmse:0.367101\tvalid-rmse:0.397049\n",
      "[30]\ttrain-rmse:0.356892\tvalid-rmse:0.394733\n",
      "[40]\ttrain-rmse:0.349935\tvalid-rmse:0.394188\n",
      "[49]\ttrain-rmse:0.344428\tvalid-rmse:0.393453\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(xgb_pars, dtrain, 50, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LGB without additional featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalid_0's rmse: 0.404022\n",
      "[200]\tvalid_0's rmse: 0.397146\n",
      "[300]\tvalid_0's rmse: 0.394226\n",
      "[400]\tvalid_0's rmse: 0.392445\n",
      "[500]\tvalid_0's rmse: 0.391152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 0.391152\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(Xtr, ytr)\n",
    "lgb_eval = lgb.Dataset(Xv, yv)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 10\n",
    "}\n",
    "gbm = lgb.train(params,lgb_train,num_boost_round=500,valid_sets=lgb_eval,early_stopping_rounds=50,verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 190,  148,  629,  496,  433,  532,    7,   77,  270,  475,  466,\n",
       "        612,  643,  377,  512,  309,  490, 1248,  478, 1892,  431,  805,\n",
       "        397,  463,  231,  185,  177,   26,  218,  421,  131,  417,  460,\n",
       "        301,  625,  403,  118,  376,  211,  148,  333,  243,  189,  371,\n",
       "        529,  432,  546,  398,  588,  345,  647,  373, 1042,  365,  610,\n",
       "        359,  302])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_im = train[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
       "       'pickup_weekday', 'pickup_hour_weekofyear', 'pickup_hour',\n",
       "       'pickup_minute', 'pickup_dt', 'pickup_week_hour', 'pickup_pca0',\n",
       "       'pickup_pca1', 'dropoff_pca0', 'dropoff_pca1', 'distance_haversine',\n",
       "       'distance_dummy_manhattan', 'direction', 'pca_manhattan',\n",
       "       'rotate_distance', 'center_latitude', 'center_longitude',\n",
       "       'pickup_cluster', 'dropoff_cluster', 'avg_speed_h_gby_pickup_hour',\n",
       "       'avg_speed_m_gby_pickup_hour', 'log_trip_duration_gby_pickup_hour',\n",
       "       'avg_speed_h_gby_pickup_date', 'avg_speed_m_gby_pickup_date',\n",
       "       'log_trip_duration_gby_pickup_date', 'avg_speed_h_gby_pickup_dt_bin',\n",
       "       'avg_speed_m_gby_pickup_dt_bin', 'log_trip_duration_gby_pickup_dt_bin',\n",
       "       'avg_speed_h_gby_pickup_week_hour', 'avg_speed_m_gby_pickup_week_hour',\n",
       "       'log_trip_duration_gby_pickup_week_hour',\n",
       "       'avg_speed_h_gby_pickup_cluster', 'avg_speed_m_gby_pickup_cluster',\n",
       "       'log_trip_duration_gby_pickup_cluster',\n",
       "       'avg_speed_h_gby_dropoff_cluster', 'avg_speed_m_gby_dropoff_cluster',\n",
       "       'log_trip_duration_gby_dropoff_cluster',\n",
       "       'avg_speed_h_center_lat_bin_center_long_bin',\n",
       "       'cnt_center_lat_bin_center_long_bin',\n",
       "       'avg_speed_h_pickup_hour_center_lat_bin_center_long_bin',\n",
       "       'cnt_pickup_hour_center_lat_bin_center_long_bin',\n",
       "       'avg_speed_h_pickup_hour_pickup_cluster',\n",
       "       'cnt_pickup_hour_pickup_cluster',\n",
       "       'avg_speed_h_pickup_hour_dropoff_cluster',\n",
       "       'cnt_pickup_hour_dropoff_cluster',\n",
       "       'avg_speed_h_pickup_cluster_dropoff_cluster',\n",
       "       'cnt_pickup_cluster_dropoff_cluster', 'count_60min',\n",
       "       'dropoff_cluster_count', 'pickup_cluster_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_im.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add weather features(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.2322\tvalid-rmse:4.23314\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.402836\tvalid-rmse:0.419421\n",
      "[20]\ttrain-rmse:0.368234\tvalid-rmse:0.395392\n",
      "[30]\ttrain-rmse:0.357873\tvalid-rmse:0.392601\n",
      "[40]\ttrain-rmse:0.349909\tvalid-rmse:0.391348\n",
      "[50]\ttrain-rmse:0.343555\tvalid-rmse:0.390658\n",
      "[59]\ttrain-rmse:0.339441\tvalid-rmse:0.390257\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 60, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bike count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25242</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-05-30 15:23:05</td>\n",
       "      <td>2016-05-30 15:52:59</td>\n",
       "      <td>-73.976485</td>\n",
       "      <td>40.759923</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20900</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24 19:56:47</td>\n",
       "      <td>2016-04-24 20:02:17</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18792</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-25 15:08:38</td>\n",
       "      <td>2016-06-25 15:15:57</td>\n",
       "      <td>-73.991908</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-74.005524</td>\n",
       "      <td>40.711464</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17420</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-28 18:14:17</td>\n",
       "      <td>2016-06-28 18:35:25</td>\n",
       "      <td>-73.986569</td>\n",
       "      <td>40.701485</td>\n",
       "      <td>-73.989900</td>\n",
       "      <td>40.714275</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22403</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-11 17:10:33</td>\n",
       "      <td>2016-06-11 17:14:44</td>\n",
       "      <td>-73.989551</td>\n",
       "      <td>40.740343</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  25242          2  2016-05-30 15:23:05  2016-05-30 15:52:59   \n",
       "1  20900          1  2016-04-24 19:56:47  2016-04-24 20:02:17   \n",
       "2  18792          1  2016-06-25 15:08:38  2016-06-25 15:15:57   \n",
       "3  17420          1  2016-06-28 18:14:17  2016-06-28 18:35:25   \n",
       "4  22403          1  2016-06-11 17:10:33  2016-06-11 17:14:44   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.976485        40.759923         -74.002150         40.730386   \n",
       "1        -74.003664        40.743174         -74.002150         40.730386   \n",
       "2        -73.991908        40.716059         -74.005524         40.711464   \n",
       "3        -73.986569        40.701485         -73.989900         40.714275   \n",
       "4        -73.989551        40.740343         -73.990093         40.737050   \n",
       "\n",
       "   trip_duration  \n",
       "0           1794  \n",
       "1            329  \n",
       "2            438  \n",
       "3           1268  \n",
       "4            251  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df = pd.read_csv('./City Bike.csv')\n",
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df['pickup_datetime'] = pd.to_datetime(bike_df['pickup_datetime'])\n",
    "bike_df.loc[:,'pickup_date'] = bike_df['pickup_datetime'].dt.date\n",
    "bike_df_date = bike_df.groupby('pickup_date').count()[['id']]\n",
    "bike_df_date.rename(columns={'id':'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df_date.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_weather_bike = pd.merge(train_merge_weather,bike_df_date,on='pickup_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23477\tvalid-rmse:4.23703\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.405177\tvalid-rmse:0.419418\n",
      "[20]\ttrain-rmse:0.365892\tvalid-rmse:0.391673\n",
      "[30]\ttrain-rmse:0.355813\tvalid-rmse:0.389887\n",
      "[40]\ttrain-rmse:0.348509\tvalid-rmse:0.388683\n",
      "[50]\ttrain-rmse:0.342712\tvalid-rmse:0.388469\n",
      "[60]\ttrain-rmse:0.338563\tvalid-rmse:0.388229\n",
      "[69]\ttrain-rmse:0.33565\tvalid-rmse:0.388111\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather_bike.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather_bike.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather_bike['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather_bike[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 70, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_date\n",
       "2016-01-01    10468497\n",
       "2016-01-02    10816222\n",
       "2016-01-03    11860433\n",
       "2016-01-04    11259185\n",
       "2016-01-05     9807448\n",
       "2016-01-06    16999310\n",
       "2016-01-07    17027029\n",
       "2016-01-08    19161629\n",
       "2016-01-09    14648225\n",
       "2016-01-10    10350752\n",
       "2016-01-11    13280885\n",
       "2016-01-12    14749292\n",
       "2016-01-13    11628534\n",
       "2016-01-14    14773092\n",
       "2016-01-15    20129422\n",
       "2016-01-16    15929398\n",
       "2016-01-17     9619881\n",
       "2016-01-18     7661812\n",
       "2016-01-19     9180914\n",
       "2016-01-20    13981120\n",
       "2016-01-21    15705667\n",
       "2016-01-22    15092621\n",
       "2016-01-27     5648088\n",
       "2016-01-28     8865156\n",
       "2016-01-29    10945332\n",
       "2016-01-30     9669152\n",
       "2016-01-31    11832568\n",
       "2016-02-01    15022661\n",
       "2016-02-02    17849845\n",
       "2016-02-03     9090400\n",
       "                ...   \n",
       "2016-06-01    48663046\n",
       "2016-06-02    41331145\n",
       "2016-06-03    29556786\n",
       "2016-06-04    43237179\n",
       "2016-06-05    19017018\n",
       "2016-06-06    39875432\n",
       "2016-06-07    37495974\n",
       "2016-06-08    27322986\n",
       "2016-06-09    40548812\n",
       "2016-06-10    40073726\n",
       "2016-06-11    35888730\n",
       "2016-06-12    38531842\n",
       "2016-06-13    35053711\n",
       "2016-06-14    40934643\n",
       "2016-06-15    41518707\n",
       "2016-06-16    30945054\n",
       "2016-06-17    44570271\n",
       "2016-06-18    48779990\n",
       "2016-06-19    46890362\n",
       "2016-06-20    40563946\n",
       "2016-06-21    36404280\n",
       "2016-06-22    41116398\n",
       "2016-06-23    36786836\n",
       "2016-06-24    40997252\n",
       "2016-06-25    41988076\n",
       "2016-06-26    40772430\n",
       "2016-06-27    32980211\n",
       "2016-06-28    34532427\n",
       "2016-06-29    38181835\n",
       "2016-06-30    37561292\n",
       "Name: trip_duration, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.groupby('pickup_date').sum()['trip_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add hoilday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_holidays = holidays.CountryHoliday('US',state='NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holidays=pd.Series([each in ny_holidays for each in train_merge_weather_bike['pickup_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_weather_bike['is_holidays'] = is_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.23477\tvalid-rmse:4.23703\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.409467\tvalid-rmse:0.425214\n",
      "[20]\ttrain-rmse:0.367339\tvalid-rmse:0.396008\n",
      "[30]\ttrain-rmse:0.356896\tvalid-rmse:0.392636\n",
      "[40]\ttrain-rmse:0.348959\tvalid-rmse:0.390592\n",
      "[50]\ttrain-rmse:0.343938\tvalid-rmse:0.389938\n",
      "[59]\ttrain-rmse:0.34045\tvalid-rmse:0.389765\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(train_merge_weather_bike.columns)\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',\n",
    "                           'trip_duration', 'pickup_date', 'avg_speed_h', 'avg_speed_m',\n",
    "                           'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin',\n",
    "                           'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train_merge_weather_bike.columns if f not in do_not_use_for_training]\n",
    "y = np.log(train_merge_weather_bike['trip_duration'].values + 1)\n",
    "Xtr, Xv, ytr, yv = train_test_split(train_merge_weather_bike[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 12,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 60, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalid_0's rmse: 0.398886\n",
      "[200]\tvalid_0's rmse: 0.391828\n",
      "[300]\tvalid_0's rmse: 0.389015\n",
      "[400]\tvalid_0's rmse: 0.387334\n",
      "[500]\tvalid_0's rmse: 0.385814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 0.385814\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(Xtr, ytr)\n",
    "lgb_eval = lgb.Dataset(Xv, yv)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 10\n",
    "}\n",
    "gbm = lgb.train(params,lgb_train,num_boost_round=500,valid_sets=lgb_eval,early_stopping_rounds=50,verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_s=pd.Series(gbm.feature_importance())\n",
    "name_s =pd.Series(feature_names)\n",
    "im_df = pd.DataFrame([feature_s,name_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_df = im_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1876</td>\n",
       "      <td>direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1166</td>\n",
       "      <td>distance_haversine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1045</td>\n",
       "      <td>avg_speed_h_pickup_cluster_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>828</td>\n",
       "      <td>rotate_distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>654</td>\n",
       "      <td>avg_speed_h_pickup_hour_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607</td>\n",
       "      <td>pickup_longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>605</td>\n",
       "      <td>log_trip_duration_gby_pickup_dt_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>604</td>\n",
       "      <td>count_60min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>570</td>\n",
       "      <td>avg_speed_h_center_lat_bin_center_long_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>547</td>\n",
       "      <td>avg_speed_h_pickup_hour_pickup_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>525</td>\n",
       "      <td>avg_speed_h_pickup_hour_center_lat_bin_center_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>513</td>\n",
       "      <td>pickup_week_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>503</td>\n",
       "      <td>pickup_pca1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>501</td>\n",
       "      <td>dropoff_latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>492</td>\n",
       "      <td>distance_dummy_manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>489</td>\n",
       "      <td>center_longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>483</td>\n",
       "      <td>pickup_dt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464</td>\n",
       "      <td>pickup_latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>451</td>\n",
       "      <td>dropoff_pca1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>445</td>\n",
       "      <td>pickup_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>440</td>\n",
       "      <td>pca_manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>432</td>\n",
       "      <td>avg_speed_h_gby_pickup_week_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>429</td>\n",
       "      <td>pickup_minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>423</td>\n",
       "      <td>avg_speed_h_gby_pickup_dt_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>418</td>\n",
       "      <td>pickup_pca0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416</td>\n",
       "      <td>dropoff_longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>408</td>\n",
       "      <td>cnt_center_lat_bin_center_long_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>406</td>\n",
       "      <td>center_latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>380</td>\n",
       "      <td>log_trip_duration_gby_pickup_week_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>365</td>\n",
       "      <td>cnt_pickup_cluster_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>332</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>330</td>\n",
       "      <td>cnt_pickup_hour_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>329</td>\n",
       "      <td>cnt_pickup_hour_pickup_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>307</td>\n",
       "      <td>avg_speed_h_gby_pickup_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>296</td>\n",
       "      <td>dropoff_pca0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>293</td>\n",
       "      <td>avg_speed_m_gby_pickup_dt_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>276</td>\n",
       "      <td>avg_speed_h_gby_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>274</td>\n",
       "      <td>pickup_cluster_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>pickup_hour_weekofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>231</td>\n",
       "      <td>log_trip_duration_gby_pickup_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>220</td>\n",
       "      <td>avg_speed_h_gby_pickup_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>203</td>\n",
       "      <td>pickup_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>199</td>\n",
       "      <td>maximum temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>190</td>\n",
       "      <td>dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>vendor_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>180</td>\n",
       "      <td>minimum temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>158</td>\n",
       "      <td>avg_speed_m_gby_dropoff_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>156</td>\n",
       "      <td>avg_speed_h_gby_pickup_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>143</td>\n",
       "      <td>average temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>141</td>\n",
       "      <td>avg_speed_m_gby_pickup_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>130</td>\n",
       "      <td>avg_speed_m_gby_pickup_week_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>passenger_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>103</td>\n",
       "      <td>avg_speed_m_gby_pickup_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>87</td>\n",
       "      <td>precipitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>pickup_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>avg_speed_m_gby_pickup_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>25</td>\n",
       "      <td>snow depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11</td>\n",
       "      <td>snow fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>is_holidays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "19  1876                                          direction\n",
       "17  1166                                 distance_haversine\n",
       "52  1045         avg_speed_h_pickup_cluster_dropoff_cluster\n",
       "21   828                                    rotate_distance\n",
       "50   654            avg_speed_h_pickup_hour_dropoff_cluster\n",
       "2    607                                   pickup_longitude\n",
       "34   605                log_trip_duration_gby_pickup_dt_bin\n",
       "54   604                                        count_60min\n",
       "44   570         avg_speed_h_center_lat_bin_center_long_bin\n",
       "48   547             avg_speed_h_pickup_hour_pickup_cluster\n",
       "46   525  avg_speed_h_pickup_hour_center_lat_bin_center_...\n",
       "12   513                                   pickup_week_hour\n",
       "14   503                                        pickup_pca1\n",
       "5    501                                   dropoff_latitude\n",
       "18   492                           distance_dummy_manhattan\n",
       "23   489                                   center_longitude\n",
       "11   483                                          pickup_dt\n",
       "3    464                                    pickup_latitude\n",
       "16   451                                       dropoff_pca1\n",
       "9    445                                        pickup_hour\n",
       "20   440                                      pca_manhattan\n",
       "35   432                   avg_speed_h_gby_pickup_week_hour\n",
       "10   429                                      pickup_minute\n",
       "32   423                      avg_speed_h_gby_pickup_dt_bin\n",
       "13   418                                        pickup_pca0\n",
       "4    416                                  dropoff_longitude\n",
       "45   408                 cnt_center_lat_bin_center_long_bin\n",
       "22   406                                    center_latitude\n",
       "37   380             log_trip_duration_gby_pickup_week_hour\n",
       "53   365                 cnt_pickup_cluster_dropoff_cluster\n",
       "..   ...                                                ...\n",
       "63   332                                              count\n",
       "51   330                    cnt_pickup_hour_dropoff_cluster\n",
       "49   329                     cnt_pickup_hour_pickup_cluster\n",
       "29   307                        avg_speed_h_gby_pickup_date\n",
       "15   296                                       dropoff_pca0\n",
       "33   293                      avg_speed_m_gby_pickup_dt_bin\n",
       "41   276                    avg_speed_h_gby_dropoff_cluster\n",
       "56   274                               pickup_cluster_count\n",
       "8    256                             pickup_hour_weekofyear\n",
       "28   231                  log_trip_duration_gby_pickup_hour\n",
       "38   220                     avg_speed_h_gby_pickup_cluster\n",
       "24   203                                     pickup_cluster\n",
       "57   199                                maximum temperature\n",
       "25   190                                    dropoff_cluster\n",
       "0    183                                          vendor_id\n",
       "58   180                                minimum temperature\n",
       "42   158                    avg_speed_m_gby_dropoff_cluster\n",
       "26   156                        avg_speed_h_gby_pickup_hour\n",
       "59   143                                average temperature\n",
       "39   141                     avg_speed_m_gby_pickup_cluster\n",
       "36   130                   avg_speed_m_gby_pickup_week_hour\n",
       "1    125                                    passenger_count\n",
       "30   103                        avg_speed_m_gby_pickup_date\n",
       "60    87                                      precipitation\n",
       "7     81                                     pickup_weekday\n",
       "27    30                        avg_speed_m_gby_pickup_hour\n",
       "62    25                                         snow depth\n",
       "61    11                                          snow fall\n",
       "6      9                                 store_and_fwd_flag\n",
       "64     5                                        is_holidays\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_df.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
